import os
import sys
import pandas as pd

# ==============================================================================
#  CRITICAL FIX: PROJ_LIB ENVIRONMENT CLASH
# ==============================================================================
# This block forces Python to use the local .drone PROJ database instead of 
# the system-wide QGIS database (which causes the version mismatch error).
# ==============================================================================
def fix_proj_path():
    # 1. Get the path to the virtual environment
    venv_base = sys.prefix
    
    # 2. Look for the proj.db file in common locations within the venv
    potential_paths = [
        # Standard pip install location for GDAL
        os.path.join(venv_base, 'Lib', 'site-packages', 'osgeo', 'data', 'proj'),
        # Standard pip install location for pyproj
        os.path.join(venv_base, 'Lib', 'site-packages', 'pyproj', 'proj_dir', 'share', 'proj'),
        # Alternate locations
        os.path.join(venv_base, 'share', 'proj'),
    ]

    found = False
    for p in potential_paths:
        if os.path.exists(os.path.join(p, 'proj.db')):
            print(f"--- SYSTEM FIX: Overriding PROJ_LIB to: {p} ---")
            os.environ['PROJ_LIB'] = p
            found = True
            break
            
    if not found:
        print("--- WARNING: Could not automatically find local proj.db. ---")
        print("    If you see 'SRS definition' errors, check your GDAL installation.")

# Apply the fix immediately before importing GDAL-dependent modules
fix_proj_path()
# ==============================================================================

# Import modules AFTER setting the environment variable
import process_metadata
import kalman_smoother
import georeference_images

# --- Configuration ---
RAW_IMAGE_DIR = "D:/WORK/Drone_Task/Drone_data/images"
OUTPUT_DIR = "final_research_output"

# Intermediate files
METADATA_CSV = "image_metadata.csv"        # Generated by smart_merge.py or extract scripts
PROCESSED_CSV = "processed_metadata.csv"   # Generated by Step 1
SMOOTHED_CSV = "kalman_smoothed_metadata.csv" # Generated by Step 2

def run_pipeline():
    print("==================================================")
    print("   STARTING DRONE GEOREFERENCING PIPELINE V3      ")
    print("==================================================")

    # ---------------------------------------------------------
    # Step 1: Process Raw Metadata
    # ---------------------------------------------------------
    print("\n--- Step 1: Processing Metadata ---")
    
    # Check if the initial metadata extraction has been done
    if not os.path.exists(METADATA_CSV):
        print(f"CRITICAL ERROR: {METADATA_CSV} is missing.")
        print("Please run 'smart_merge.py' (if using MRK) or extraction script first.")
        return
    
    # Run the cleaning logic (removes duplicates, converts altitude to meters)
    # This reads image_metadata.csv and saves processed_metadata.csv
    process_metadata.process_metadata()
    
    if not os.path.exists(PROCESSED_CSV):
        print("Error: Step 1 failed. processed_metadata.csv was not created.")
        return

    # ---------------------------------------------------------
    # Step 2: Advanced Temporal Refinement (Kalman Filter)
    # ---------------------------------------------------------
    print("\n--- Step 2: Applying Kalman Filter (Research-Grade) ---")
    
    # Apply the physics-based smoothing
    # This reads processed_metadata.csv and saves kalman_smoothed_metadata.csv
    kalman_smoother.apply_kalman_filter(PROCESSED_CSV, SMOOTHED_CSV)
    
    if not os.path.exists(SMOOTHED_CSV):
        print("Error: Step 2 failed. kalman_smoothed_metadata.csv was not created.")
        return

    # ---------------------------------------------------------
    # Step 3: Georeferencing & File Generation
    # ---------------------------------------------------------
    print("\n--- Step 3: Georeferencing & Generating GeoTIFFs ---")
    
    # Load the optimized data
    imageData = pd.read_csv(SMOOTHED_CSV)
    
    # Create output directory if it doesn't exist
    if not os.path.exists(OUTPUT_DIR):
        os.makedirs(OUTPUT_DIR)
    
    # Run the core georeferencing engine
    # NOTE: You can adjust cameraPitch and cameraYaw here if the map alignment is wrong.
    georeference_images.georeference_images(
        imageData=imageData,
        imageDirectory=RAW_IMAGE_DIR,
        outputDirectory=OUTPUT_DIR,
        droneParmsLogPath=None, # Not needed as we are using image metadata directly
        cameraPitch=30.0,       # Standard Oblique Pitch
        cameraYaw=90,           # Side-facing camera
        suffix="_final"         # Output files will end in _final.tif
    )

    print("\n==================================================")
    print("   PIPELINE COMPLETE")
    print(f"   Success! Research-grade outputs are in: {OUTPUT_DIR}")
    print("==================================================")

if __name__ == "__main__":
    run_pipeline()